import multiprocessing
import threading
import random
import time
import getpass
import os
import psutil
from datetime import datetime
from queue import Empty


class Logger:
    def __init__(self, log_file='app.log'):
        self.log_file = log_file
        self.username = getpass.getuser()
        
    def log(self, level, message):
        timestamp = datetime.now().strftime("%d.%m.%Y %H:%M:%S")
        log_entry = f"[{level}] [{timestamp}] [{self.username}] - {message}\n"
        
        with open(self.log_file, 'a') as f:
            f.write(log_entry)


def bubble_sort(arr):
    n = len(arr)
    for i in range(n):
        for j in range(0, n-i-1):
            if arr[j] > arr[j+1]:
                arr[j], arr[j+1] = arr[j+1], arr[j]
    return arr


def merge_sorted_arrays(arrays):
    result = []
    pointers = [0] * len(arrays)
    
    while True:
        min_val = None
        min_idx = -1
        
        for i in range(len(arrays)):
            if pointers[i] < len(arrays[i]):
                current = arrays[i][pointers[i]]
                if min_val is None or current < min_val:
                    min_val = current
                    min_idx = i
        
        if min_idx == -1:
            break
            
        result.append(min_val)
        pointers[min_idx] += 1
    
    return result


def save_result_thread(result, filename, logger):
    try:
        with open(filename, 'a') as f:
            f.write(','.join(map(str, result)))
            f.write('\n')
        logger.log("INFO", f"Фоновый поток сохранил часть массива в {filename}")
    except Exception as e:
        logger.log("ERROR", f"Ошибка в фоновом потоке сохранения: {str(e)}")


def sort_worker(arr, result_queue, logger):
    try:
        logger.log("INFO", f"Начата сортировка части массива размером {len(arr)}")
        sorted_arr = bubble_sort(arr)

        save_thread = threading.Thread(
            target=save_result_thread,
            args=(sorted_arr, "sorted_parts.txt", logger)
        )
        save_thread.daemon = True
        save_thread.start()
        
        result_queue.put(sorted_arr)
        logger.log("INFO", "Сортировка части массива завершена")

    except Exception as e:
        logger.log("ERROR", f"Ошибка при сортировке: {str(e)}")
        result_queue.put(None)


def get_available_processes():
    total_cores = os.cpu_count()
    cpu_percent = psutil.cpu_percent(interval=1)
    available_ratio = (100 - cpu_percent) / 100
    available_processes = int(total_cores * available_ratio)
    return max(1, min(available_processes, total_cores))


def main():
    main_logger = Logger()
    
    try:
        main_logger.log("INFO", "Программа запущена")

        n = int(input("Введите количество элементов в массиве: "))
        main_logger.log("INFO", f"Пользователь ввел размер массива: {n}")

        arr = [random.randint(0, 1000) for _ in range(n)]

        available_processes = get_available_processes()
        max_processes = min(available_processes, os.cpu_count())
        
        print(f"Доступно процессов: {max_processes} (из {os.cpu_count()})")
        num_processes = int(input(f"Введите количество процессов для сортировки (1-{max_processes}): "))
        
        if num_processes < 1 or num_processes > max_processes:
            raise ValueError("Недопустимое количество процессов")
            
        main_logger.log("INFO", f"Пользователь выбрал {num_processes} процессов для сортировки")

        with open("sorted_parts.txt", 'a') as f:
            f.write(f"\nЗапуск программы\n")
        
        result_queue = multiprocessing.Queue()
        processes = []

        chunk_size = n // num_processes
        chunks = [arr[i*chunk_size:(i+1)*chunk_size] for i in range(num_processes-1)]
        chunks.append(arr[(num_processes-1)*chunk_size:])

        for chunk in chunks:
            p = multiprocessing.Process(
                target=sort_worker,
                args=(chunk, result_queue, Logger())
            )
            processes.append(p)
            p.start()

        sorted_chunks = []
        for _ in range(num_processes):
            result = result_queue.get()
            if result is not None:
                sorted_chunks.append(result)

        for p in processes:
            p.join()

        final_sorted = merge_sorted_arrays(sorted_chunks)

        with open('final_sorted.txt', 'a') as f:
            f.write(f"\Отсортированный массив\n")
            f.write(','.join(map(str, final_sorted)))
            f.write('\n')
        
        main_logger.log("INFO", "Отсортированный массив сохранен в final_sorted.txt")
        print("Сортировка завершена. Результаты сохранены в final_sorted.txt (Отсортированный массив) и sorted_parts.txt (Неотсортированный список)")
        
    except ValueError as ve:
        main_logger.log("ERROR", f"Ошибка ввода: {str(ve)}")
        print(f"Ошибка: {str(ve)}")
    except Exception as e:
        main_logger.log("ERROR", f"Неожиданная ошибка: {str(e)}")
        print(f"Произошла ошибка: {str(e)}")
    finally:
        main_logger.log("INFO", "Программа завершена")


if __name__ == "__main__":
    main()
